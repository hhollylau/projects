{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# futcurves — real SR3 data test\n",
    "\n",
    "End-to-end test of the library using **real Databento SR3 data** stored on Google Drive.\n",
    "\n",
    "1. Authenticate Google Drive & download SR3 parquet\n",
    "2. Parse contracts into `meta` and `panel` DataFrames\n",
    "3. Build rolling universe\n",
    "4. Build strip curve + holdings (smoothstep roll)\n",
    "5. Inspect roll blending around a real roll date\n",
    "6. Generate contract-level orders\n",
    "7. Visualise curve, term structure, returns\n",
    "\n",
    "**Before publishing:** remove `credentials.json`, `token.pickle`, and any hardcoded API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, io, pickle, re\n",
    "from datetime import datetime\n",
    "\n",
    "from futcurves import (\n",
    "    RollPolicy,\n",
    "    build_rolling_universe,\n",
    "    build_strip_curve,\n",
    "    position_to_contract_orders,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Google Drive — download SR3 parquet\n",
    "\n",
    "This pulls `sr3_curve_daily_3years.parquet` from the `Databento_Data` folder on your Drive.\n",
    "If you already have it locally, skip the download cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "\n",
    "SCOPES = [\"https://www.googleapis.com/auth/drive.file\"]\n",
    "\n",
    "def authenticate_google_drive():\n",
    "    creds = None\n",
    "    if os.path.exists(\"token.pickle\"):\n",
    "        with open(\"token.pickle\", \"rb\") as f:\n",
    "            creds = pickle.load(f)\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\"credentials.json\", SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open(\"token.pickle\", \"wb\") as f:\n",
    "            pickle.dump(creds, f)\n",
    "    return build(\"drive\", \"v3\", credentials=creds)\n",
    "\n",
    "\n",
    "def download_from_drive(service, file_name, folder_name=\"Databento_Data\"):\n",
    "    q = f\"name='{folder_name}' and mimeType='application/vnd.google-apps.folder' and trashed=false\"\n",
    "    folders = service.files().list(q=q, spaces=\"drive\", fields=\"files(id)\").execute().get(\"files\", [])\n",
    "    if not folders:\n",
    "        raise FileNotFoundError(f\"Folder '{folder_name}' not found on Drive\")\n",
    "    folder_id = folders[0][\"id\"]\n",
    "    q = f\"name='{file_name}' and '{folder_id}' in parents and trashed=false\"\n",
    "    files = service.files().list(q=q, spaces=\"drive\", fields=\"files(id)\").execute().get(\"files\", [])\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"File '{file_name}' not found in '{folder_name}'\")\n",
    "    request = service.files().get_media(fileId=files[0][\"id\"])\n",
    "    fh = io.FileIO(file_name, \"wb\")\n",
    "    downloader = MediaIoBaseDownload(fh, request)\n",
    "    done = False\n",
    "    while not done:\n",
    "        status, done = downloader.next_chunk()\n",
    "    print(f\"Downloaded {file_name}\")\n",
    "    return file_name\n",
    "\n",
    "\n",
    "drive_service = authenticate_google_drive()\n",
    "print(\"Google Drive authenticated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARQUET_FILE = \"sr3_curve_daily_3years.parquet\"\n",
    "\n",
    "if not os.path.exists(PARQUET_FILE):\n",
    "    download_from_drive(drive_service, PARQUET_FILE)\n",
    "\n",
    "df_raw = pd.read_parquet(PARQUET_FILE)\n",
    "print(f\"Loaded {len(df_raw):,} rows\")\n",
    "print(f\"Date range: {df_raw.index.min()} to {df_raw.index.max()}\")\n",
    "print(f\"Columns: {df_raw.columns.tolist()}\")\n",
    "print(f\"Unique symbols: {df_raw['symbol'].nunique()}\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parse into `meta` and `panel`\n",
    "\n",
    "Filter to single-leg quarterly contracts (`SR3[HMUZ]\\d`), build the meta and panel DataFrames that `futcurves` expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to single-leg quarterly contracts\n",
    "mask = df_raw[\"symbol\"].str.match(r\"^SR3[HMUZ]\\d$\")\n",
    "df = df_raw[mask].copy()\n",
    "print(f\"After filter: {len(df):,} rows, {df['symbol'].nunique()} contracts\")\n",
    "print(f\"Contracts: {sorted(df['symbol'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTH_MAP = {\"H\": 3, \"M\": 6, \"U\": 9, \"Z\": 12}\n",
    "\n",
    "\n",
    "def sr3_expiry(symbol: str) -> pd.Timestamp:\n",
    "    \"\"\"Estimate expiry as 3rd Wednesday of the contract month.\"\"\"\n",
    "    month = MONTH_MAP[symbol[3]]\n",
    "    year = 2020 + int(symbol[4])\n",
    "    # 3rd Wednesday: find first day of month, advance to first Wed, then +14 days\n",
    "    first = pd.Timestamp(year, month, 1)\n",
    "    wed_offset = (2 - first.weekday()) % 7  # days until first Wednesday\n",
    "    third_wed = first + pd.Timedelta(days=wed_offset + 14)\n",
    "    return third_wed\n",
    "\n",
    "\n",
    "contracts = sorted(df[\"symbol\"].unique())\n",
    "meta = pd.DataFrame({\n",
    "    \"contract\": contracts,\n",
    "    \"expiry\": [sr3_expiry(c) for c in contracts],\n",
    "})\n",
    "# last_trade_date is typically 2 bdays before IMM expiry for SR3\n",
    "meta[\"last_trade_date\"] = meta[\"expiry\"] - pd.tseries.offsets.BDay(2)\n",
    "\n",
    "print(f\"meta: {len(meta)} contracts\")\n",
    "meta.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build panel: ts, contract, price\n",
    "df[\"date\"] = pd.to_datetime(df.index).normalize()\n",
    "if df[\"date\"].dt.tz is not None:\n",
    "    df[\"date\"] = df[\"date\"].dt.tz_localize(None)\n",
    "\n",
    "panel = df[[\"date\", \"symbol\", \"close\"]].rename(\n",
    "    columns={\"date\": \"ts\", \"symbol\": \"contract\", \"close\": \"price\"}\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(f\"panel: {len(panel):,} rows\")\n",
    "print(f\"Date range: {panel['ts'].min().date()} to {panel['ts'].max().date()}\")\n",
    "panel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build the rolling universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_positions = 20\n",
    "start = str(panel[\"ts\"].min().date())\n",
    "end = str(panel[\"ts\"].max().date())\n",
    "\n",
    "universe = build_rolling_universe(meta, start, end, n_positions=n_positions)\n",
    "print(f\"universe shape: {universe.shape}\")\n",
    "print(f\"{start} to {end}\")\n",
    "universe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When does the front contract roll?\n",
    "front = universe[1]\n",
    "roll_dates = front[front != front.shift()].dropna()\n",
    "print(f\"{len(roll_dates)} front contract rolls:\")\n",
    "for d, c in roll_dates.items():\n",
    "    print(f\"  {d.date()}  -> {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build strip curve + holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_policy = RollPolicy(\n",
    "    weight_fn=\"smoothstep\",\n",
    "    roll_window_bdays=7,\n",
    "    roll_end_offset_bdays=2,\n",
    ")\n",
    "\n",
    "curve_px, holdings = build_strip_curve(\n",
    "    panel, universe, meta, n_positions=n_positions, roll_policy=roll_policy\n",
    ")\n",
    "\n",
    "print(f\"curve_px shape: {curve_px.shape}\")\n",
    "print(f\"NaN cells: {curve_px.isna().sum().sum()}\")\n",
    "curve_px.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inspect roll blending around a real roll date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the second roll and show holdings for positions 1-5 through the window\n",
    "roll_d = roll_dates.index[min(1, len(roll_dates) - 1)]\n",
    "window = pd.date_range(\n",
    "    roll_d - pd.tseries.offsets.BDay(10),\n",
    "    roll_d + pd.tseries.offsets.BDay(3),\n",
    "    freq=\"B\",\n",
    ")\n",
    "\n",
    "print(f\"Roll window around {roll_d.date()}\\n\")\n",
    "for d in window:\n",
    "    if d not in holdings:\n",
    "        continue\n",
    "    h1 = holdings[d].get(1, {})\n",
    "    parts = \"  \".join(f\"{c}:{w:.3f}\" for c, w in h1.items())\n",
    "    print(f\"  {d.date()}  pos1: {parts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blend weights table for position 1\n",
    "blend_data = []\n",
    "for d in window:\n",
    "    if d in holdings:\n",
    "        h = holdings[d].get(1, {})\n",
    "        blend_data.append({\"date\": d, **{f\"w({c})\": w for c, w in h.items()}})\n",
    "\n",
    "blend_df = pd.DataFrame(blend_data).set_index(\"date\").fillna(0)\n",
    "blend_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Position signal -> contract orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_date = curve_px.index[-1]\n",
    "notional = 1_000_000.0\n",
    "\n",
    "for pos in [1, 5, 10, 20]:\n",
    "    orders = position_to_contract_orders(\n",
    "        holdings, example_date, position=pos, target_notional=-notional\n",
    "    )\n",
    "    print(f\"pos {pos:>2d}: {orders}\")\n",
    "\n",
    "print(f\"\\nDate: {example_date.date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As Order dataclasses\n",
    "order_objs = position_to_contract_orders(\n",
    "    holdings, example_date, position=5, target_notional=-notional, as_dataclasses=True\n",
    ")\n",
    "for o in order_objs:\n",
    "    print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip curve time series\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "for pos in [1, 5, 10, 15, 20]:\n",
    "    ax.plot(curve_px.index, curve_px[pos], label=f\"pos {pos}\", alpha=0.8)\n",
    "ax.set_title(\"SR3 strip curve (real data, smoothstep roll)\")\n",
    "ax.set_ylabel(\"price\")\n",
    "ax.legend(ncol=5)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term structure snapshots (evenly spaced)\n",
    "n_snapshots = 6\n",
    "snap_idx = np.linspace(0, len(curve_px) - 1, n_snapshots, dtype=int)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "for i in snap_idx:\n",
    "    d = curve_px.index[i]\n",
    "    ax.plot(\n",
    "        range(1, n_positions + 1),\n",
    "        curve_px.iloc[i].values,\n",
    "        marker=\"o\", markersize=4, label=str(d.date()),\n",
    "    )\n",
    "ax.set_xlabel(\"position\")\n",
    "ax.set_ylabel(\"price\")\n",
    "ax.set_title(\"SR3 term structure snapshots\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns heatmap\n",
    "rets = curve_px.pct_change().dropna()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "vbound = rets.values[np.isfinite(rets.values)]\n",
    "vlim = np.percentile(np.abs(vbound), 99)\n",
    "im = ax.pcolormesh(\n",
    "    rets.index, rets.columns, rets.values.T,\n",
    "    cmap=\"RdBu_r\", vmin=-vlim, vmax=vlim, shading=\"auto\",\n",
    ")\n",
    "fig.colorbar(im, ax=ax, label=\"daily return\")\n",
    "ax.set_ylabel(\"position\")\n",
    "ax.set_title(\"SR3 strip curve daily returns\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position return correlations\n",
    "corr = rets.corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 7))\n",
    "im = ax.imshow(corr.values, cmap=\"RdBu_r\", vmin=corr.values.min(), vmax=1.0)\n",
    "ax.set_xticks(range(n_positions))\n",
    "ax.set_xticklabels(range(1, n_positions + 1))\n",
    "ax.set_yticks(range(n_positions))\n",
    "ax.set_yticklabels(range(1, n_positions + 1))\n",
    "ax.set_title(\"Position return correlations\")\n",
    "fig.colorbar(im, ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare roll weight functions\n",
    "u = np.linspace(0, 1, 200)\n",
    "smoothstep = 3 * u**2 - 2 * u**3\n",
    "linear = u\n",
    "k = 10.0\n",
    "logistic_raw = 1 / (1 + np.exp(-k * (u - 0.5)))\n",
    "v0 = 1 / (1 + np.exp(-k * (-0.5)))\n",
    "v1 = 1 / (1 + np.exp(-k * (0.5)))\n",
    "logistic = np.clip((logistic_raw - v0) / (v1 - v0), 0, 1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(u, linear, label=\"linear\")\n",
    "ax.plot(u, smoothstep, label=\"smoothstep\", linewidth=2)\n",
    "ax.plot(u, logistic, label=\"logistic (k=10)\", linestyle=\"--\")\n",
    "ax.set_xlabel(\"roll progress (u)\")\n",
    "ax.set_ylabel(\"weight on next contract\")\n",
    "ax.set_title(\"Roll weight functions\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Delete the downloaded parquet to save local space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(PARQUET_FILE):\n",
    "    os.remove(PARQUET_FILE)\n",
    "    print(f\"Deleted {PARQUET_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}